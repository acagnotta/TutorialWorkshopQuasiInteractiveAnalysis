{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4213965a-36f5-4afb-aa9a-f4168cbb483b",
   "metadata": {},
   "source": [
    "**Tutorial T'-> tZ analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf1ce47-e2f0-48f4-8e4b-b0fa9f1bacac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters\n",
    "sched_port    = 23356 #Dask port\n",
    "nmaxpartition = 50\n",
    "distributed   = False#True#\n",
    "do_variations = False#True#\n",
    "hist_folder   = \"histos\"\n",
    "\n",
    "if do_variations == True:\n",
    "    variations = [\"nominal\", \"pu\", \"jer\", \"jesTotal\"]\n",
    "else :\n",
    "    variations = [\"nominal\"]\n",
    "\n",
    "in_dataset = [\"TprimeToTZ_1800_2022\"]#\"TT_semilep_2022\" #\"TT_hadr_2022\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e16aaf3-78d5-4a3c-851c-21f771dcf586",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ROOT\n",
    "import os\n",
    "from samples import *\n",
    "from variables import *\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "from dask.distributed import Client\n",
    "ROOT.RDF.Experimental.Distributed.open_files_locally = False\n",
    "\n",
    "os.environ['X509_CERT_DIR'] = \"/cvmfs/grid.cern.ch/etc/grid-security/certificates/\"\n",
    "os.environ['X509_USER_PROXY'] = \"/tmp/x509up_u0\"\n",
    "print(os.environ.get(\"X509_USER_PROXY\"), os.environ.get(\"X509_CERT_DIR\"))\n",
    "\n",
    "\n",
    "if distributed:\n",
    "    nfiles_max = 1000\n",
    "else:\n",
    "    nfiles_max = 1  #######\n",
    "\n",
    "#output histos folder\n",
    "folder = \"./results/\"\n",
    "\n",
    "print(\"local folder histos: {}\".format(folder))\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "repohisto = folder+hist_folder+\"/\"\n",
    "if not os.path.exists(repohisto):\n",
    "    os.mkdir(repohisto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3271c9-56c5-4ee1-a501-f85177699ab8",
   "metadata": {},
   "source": [
    "- Import of utils from variables.py\n",
    "Regions, Variables\n",
    "\n",
    "- syncro between in_dataset and sample_dict (from sample.py) to syncronize labels and other featurs of the dataset \n",
    "- import of samples_dict.json to load files list (path to reach them on tier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f446ef-90d9-46e8-ad16-8ded4fa2fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_def = regions # ---> see variables.py\n",
    "print(\"Regions to book: \")\n",
    "for r in regions_def.keys():\n",
    "    print(\"  \"+r)\n",
    "    \n",
    "sample_file = open(\"dict_samples_2022.json\", \"rb\")\n",
    "samples = json.load(sample_file)\n",
    "sample_file.close()\n",
    "\n",
    "var = vars  # ---> variables.py\n",
    "\n",
    "print(\"Variables for histograms :\")\n",
    "print([v._name for v in var])\n",
    "\n",
    "datasets = []\n",
    "for in_d in in_dataset:\n",
    "    if not in_d in sample_dict.keys():\n",
    "        print(\"Check the in_dataset string... \", sample_dict.keys())\n",
    "    else : \n",
    "        datasets.append(sample_dict[in_d])\n",
    "print(\"Datasets to process : \", [d.label for d in datasets])\n",
    "\n",
    "\n",
    "chain = {}\n",
    "ntot_events = {}\n",
    "for d in datasets:\n",
    "    if hasattr(d, \"components\"):\n",
    "        samples_list = d.components\n",
    "    else:\n",
    "        samples_list = [d]\n",
    "    chain[d.label] = {}\n",
    "    ntot_events[d.label] = {}\n",
    "    for s in samples_list:\n",
    "        if distributed: \n",
    "            nfiles = len(samples[d.label][s.label]['strings'])\n",
    "            for i, string in enumerate(samples[d.label][s.label]['strings']): \n",
    "                if distributed:\n",
    "                    samples[d.label][s.label]['strings'][i] = string.replace(\"root://cms-xrd-global.cern.ch/\", \"davs://stwebdav.pi.infn.it:8443/cms/\")\n",
    "                else:\n",
    "                    samples[d.label][s.label]['strings'][i] = string.replace(\"root://cms-xrd-global.cern.ch/\", \"root://stormgf2.pi.infn.it/\")\n",
    "            chain[d.label][s.label] = samples[d.label][s.label]['strings']\n",
    "        else: \n",
    "            nfiles = nfiles_max\n",
    "            for i, string in enumerate(samples[d.label][s.label]['strings']): \n",
    "                if distributed: samples[d.label][s.label]['strings'][i] = string.replace(\"root://cms-xrd-global.cern.ch/\", \"davs://stwebdav.pi.infn.it:8443/cms/\")\n",
    "                else: samples[d.label][s.label]['strings'][i] = string.replace(\"root://cms-xrd-global.cern.ch/\", \"root://stormgf2.pi.infn.it/\")\n",
    "            chain[d.label][s.label] = samples[d.label][s.label]['strings'][:nfiles]\n",
    "        if not \"Data\" in s.label: ntot_events[d.label][s.label] = np.sum(samples[d.label][s.label]['ntot'][:nfiles])\n",
    "        else: ntot_events[d.label][s.label] = None\n",
    "        print(\"Dataset : \"+s.label)\n",
    "        print(\"# of files to process : \", nfiles)\n",
    "        if distributed and len(chain[d.label][s.label])>2:\n",
    "            print(\"files strings :\\n  {}\\n  {}\\n  ... \\n  {}\\n  {}\".format(chain[d.label][s.label][0], chain[d.label][s.label][1], chain[d.label][s.label][-2], chain[d.label][s.label][-1]))\n",
    "        else :\n",
    "            print(\"files strings :\\n  {}\".format(chain[d.label][s.label][0]))\n",
    "        print(\"# of total events in the files to process (MC only, if Data the number is None) : \", ntot_events[d.label][s.label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a9be5b-2e52-431b-9709-ee1c3e639b68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialization of clusters\n",
    "\n",
    "# upload the proxyfile to the Dask workers to make them able to access data on the grid \n",
    "\n",
    "from distributed.diagnostics.plugin import UploadFile\n",
    "def set_proxy(dask_worker):\n",
    "    import os\n",
    "    import shutil\n",
    "    working_dir = dask_worker.local_directory\n",
    "    proxy_name = 'x509up_u0'\n",
    "    os.environ['X509_USER_PROXY'] = working_dir + '/' + proxy_name\n",
    "    os.environ['X509_CERT_DIR']=\"/cvmfs/grid.cern.ch/etc/grid-security/certificates/\"\n",
    "    shutil.copyfile(working_dir + '/' + proxy_name, working_dir + '/../../../proxy')    \n",
    "    os.environ['EXTRA_CLING_ARGS'] = \"-O2\"\n",
    "    return os.environ.get(\"X509_USER_PROXY\"), os.environ.get(\"X509_CERT_DIR\")\n",
    "\n",
    "text_file = open(\"postselection.h\", \"r\")\n",
    "data = text_file.read()\n",
    "def my_initialization_function():\n",
    "    print(ROOT.gInterpreter.ProcessLine(\".O\"))\n",
    "    ROOT.gInterpreter.Declare('{}'.format(data))\n",
    "    print(\"end of initialization\")\n",
    "\n",
    "# set up everything properly\n",
    "if distributed == True:\n",
    "    RDataFrame = ROOT.RDF.Experimental.Distributed.Dask.RDataFrame\n",
    "    client = Client(address=\"tcp://127.0.0.1:\"+str(sched_port))\n",
    "    client.restart()\n",
    "    # client.register_worker_plugin(UploadFile(\"/tmp/x509up_u0\"))\n",
    "    client.register_plugin(UploadFile(\"/tmp/x509up_u0\"))\n",
    "    client.run(set_proxy)\n",
    "    ROOT.RDF.Experimental.Distributed.initialize(my_initialization_function)\n",
    "else:\n",
    "    RDataFrame = ROOT.RDataFrame\n",
    "    my_initialization_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963af90a-de0c-44a7-9b64-3927c34eeffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### utils ###################\n",
    "def cut_string(cut):\n",
    "    return cut.replace(\" \", \"\").replace(\"&&\",\"_\").replace(\">\",\"_g_\").replace(\".\",\"_\").replace(\"==\",\"_e_\")\n",
    "\n",
    "################### preselection ###############\n",
    "def preselection(df):\n",
    "    df = df.Define(\"GoodJet_idx\", \"GetGoodJet(Jet_pt_nominal, Jet_eta, Jet_jetId)\")\n",
    "    df = df.Define(\"nGoodJet\", \"nGoodJet(GoodJet_idx)\")\n",
    "    df = df.Define(\"GoodFatJet_idx\", \"GetGoodFatJet(FatJet_pt_nominal, FatJet_eta, FatJet_jetId, FatJet_particleNetWithMass_TvsQCD)\")\n",
    "    df = df.Define(\"nGoodFatJet\", \"GoodFatJet_idx.size()\")\n",
    "    df = df.Define(\"minDeltaPhi\", \"min_DeltaPhi(PuppiMET_T1_phi_nominal, Jet_phi, GoodJet_idx)\")\n",
    "    df = df.Define(\"nVetoElectron\", \"nVetoElectron(Electron_pt, Electron_cutBased, Electron_eta)\")\n",
    "    df = df.Define(\"nVetoMuon\", \"nVetoMuon(Muon_pt, Muon_eta, Muon_looseId)\")\n",
    "    \n",
    "    df = df.Filter(\"nGoodFatJet>0 \", \"jet presel\")\n",
    "    df = df.Filter(\"nVetoElectron+nVetoMuon>0 \", \"Lepton Veto\")\n",
    "    df = df.Filter(\"minDeltaPhi>0.6\", \"MinDeltaPhi cut\")\n",
    "    \n",
    "    df = df.Define(\"nForwardJet\", \"nForwardJet(Jet_pt_nominal, Jet_jetId, Jet_eta)\")    \n",
    "\n",
    "    return df\n",
    "\n",
    "############### trigger selection #####################\n",
    "def trigger_filter(df):\n",
    "    hlt_met = \"(HLT_PFMET120_PFMHT120_IDTight || HLT_PFMETNoMu120_PFMHTNoMu120_IDTight)\"\n",
    "    df_trig = df.Filter(hlt_met, \"triggerMET\")\n",
    "    return df_trig\n",
    "\n",
    "############### top selection ########################\n",
    "def select_top(df):\n",
    "    # return indices of the FatJet with particleNet score over the thresholds \n",
    "    # df_goodtop      = df.Define(\"GoodTopMer_idx\", \"select_TopMer(FatJet_particleNetWithMass_TvsQCD, GoodFatJet_idx)\")\n",
    "        \n",
    "    df_topselected  = df.Define(\"Top_idx\", \"select_bestTop(FatJet_particleNetWithMass_TvsQCD, GoodFatJet_idx)\")\n",
    "    \n",
    "    df_topvariables = df_topselected.Define(\"Top_pt\", \"FatJet_pt_nominal[GoodFatJet_idx[Top_idx]]\")\\\n",
    "                        .Define(\"Top_eta\", \"FatJet_eta[GoodFatJet_idx[Top_idx]]\")\\\n",
    "                        .Define(\"Top_phi\", \"FatJet_phi[GoodFatJet_idx[Top_idx]]\")\\\n",
    "                        .Define(\"Top_mass\", \"FatJet_mass_nominal[GoodFatJet_idx[Top_idx]]\")\\\n",
    "                        .Define(\"Top_score\", \"FatJet_particleNetWithMass_TvsQCD[GoodFatJet_idx[Top_idx]]\")\n",
    "    return df_topvariables\n",
    "    \n",
    "def energetic_variations(df):\n",
    "    df_sys = df.Vary([\"Jet_pt_nominal\", \"Jet_mass_nominal\", \"PuppiMET_T1_pt_nominal_vec\", \"PuppiMET_T1_phi_nominal_vec\", \"TopMixed_pt_nominal\", \"TopResolved_pt_nominal\", \"TopMixed_mass_nominal\", \"TopResolved_mass_nominal\",  \"TopMixed_TopScore_nominal\", \"TopResolved_TopScore_nominal\"], \"RVec<RVec<RVec<float>>>{{Jet_pt_jerdown, Jet_pt_jerup}, {Jet_mass_jerdown, Jet_mass_jerup}, {PuppiMET_T1_pt_jerdown_vec, PuppiMET_T1_pt_jerup_vec}, {PuppiMET_T1_phi_jerdown_vec, PuppiMET_T1_phi_jerup_vec}, {TopMixed_pt_jerdown, TopMixed_pt_jerup}, {TopResolved_pt_jerdown, TopResolved_pt_jerup}, {TopMixed_mass_jerdown, TopMixed_mass_jerup}, {TopResolved_mass_jerdown, TopResolved_mass_jerup}, {TopMixed_TopScore_jerdown, TopMixed_TopScore_jerup}, {TopResolved_TopScore_jerdown, TopResolved_TopScore_jerup}}\", variationTags=[\"down\", \"up\"], variationName=\"jer\")\\\n",
    "               .Vary([\"Jet_pt_nominal\", \"Jet_mass_nominal\", \"PuppiMET_T1_pt_nominal_vec\", \"PuppiMET_T1_phi_nominal_vec\", \"TopMixed_pt_nominal\", \"TopResolved_pt_nominal\", \"TopMixed_mass_nominal\", \"TopResolved_mass_nominal\",  \"TopMixed_TopScore_nominal\", \"TopResolved_TopScore_nominal\"], \"RVec<RVec<RVec<float>>>{{Jet_pt_jesTotaldown, Jet_pt_jesTotalup}, {Jet_mass_jesTotaldown, Jet_mass_jesTotalup}, {PuppiMET_T1_pt_jesTotaldown_vec, PuppiMET_T1_pt_jesTotalup_vec}, {PuppiMET_T1_phi_jesTotaldown_vec, PuppiMET_T1_phi_jesTotalup_vec}, {TopMixed_pt_jesTotaldown, TopMixed_pt_jesTotalup}, {TopResolved_pt_jesTotaldown, TopResolved_pt_jesTotalup}, {TopMixed_mass_jesTotaldown, TopMixed_mass_jesTotalup}, {TopResolved_mass_jesTotaldown, TopResolved_mass_jesTotalup}, {TopMixed_TopScore_jesTotaldown, TopMixed_TopScore_jesTotalup}, {TopResolved_TopScore_jesTotaldown, TopResolved_TopScore_jesTotalup}}\", variationTags=[\"down\", \"up\"], variationName=\"jesTotal\")\n",
    "    return df_sys\n",
    "\n",
    "def SF_variations(df):\n",
    "    df_sys = df.Vary(\"puWeight\", \"RVec<float>{puWeightDown, puWeightUp}\", variationTags=[\"down\", \"up\"], variationName=\"pu\")\n",
    "    return df_sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0bf61-b2ab-422e-8baf-9abba2b984cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bookhisto(df, regions_def, var):\n",
    "    h_ = {}\n",
    "    for reg in regions_def.keys():\n",
    "        h_[reg] = {}\n",
    "        for v in var:\n",
    "            if v._MConly and not sampleflag: \n",
    "                continue\n",
    "            else:\n",
    "                # print(v._name+\"_\"+reg)\n",
    "                if regions_def[reg] == \"\":\n",
    "                    h_[reg][v._name]= df.Histo1D((v._name+\"_\"+reg,\" ;\"+v._title+\"\", v._nbins, v._xmin, v._xmax), v._name, \"w_nominal\")\n",
    "                else:\n",
    "                    h_[reg][v._name]= df.Filter(regions_def[reg]).Histo1D((v._name+\"_\"+reg,\" ;\"+v._title, v._nbins, v._xmin, v._xmax), v._name, \"w_nominal\")\n",
    "    return h_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37967949-f502-4c77-9ceb-dd04f8062cd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def savehisto(d, dict_h, regions_def, var):\n",
    "    histo = {reg: {v._name: ROOT.TH1D(v._name+\"_\"+reg,\" ;\"+v._title+\"\", v._nbins, v._xmin, v._xmax) for v in var} for reg in regions_def.keys()}\n",
    "    isMC=True\n",
    "    if \"Data\" in d.label: isMC = False\n",
    "    if hasattr(d, \"components\"):\n",
    "        s_list = d.components\n",
    "    else:\n",
    "        s_list = [d]\n",
    "    \n",
    "    for s in s_list:\n",
    "        outfile = ROOT.TFile.Open(repohisto+s.label+'.root', \"RECREATE\")\n",
    "\n",
    "        for n, vari in enumerate(variations):\n",
    "            for reg in regions_def.keys():\n",
    "                for v in var:\n",
    "                    if v._MConly and not isMC:\n",
    "                        continue\n",
    "                    else:\n",
    "                        # da capire come fare il getvalue e dividere le variazioni\n",
    "                        if isMC:\n",
    "                            if do_variations:\n",
    "                                if vari=='nominal':\n",
    "                                    h1 = dict_h[d.label][s.label][reg][v._name][\"nominal\"]\n",
    "                                    h1.SetName(h1.GetName()+\"_nominal\")\n",
    "                                    nbins = h1.GetNbinsX()\n",
    "                                    h1.SetBinContent(1, h1.GetBinContent(0) + h1.GetBinContent(1))\n",
    "                                    h1.SetBinError(1, math.sqrt(pow(h1.GetBinError(0),2) + pow(h1.GetBinError(1),2)))\n",
    "                                    h1.SetBinContent(nbins, h1.GetBinContent(nbins) + h1.GetBinContent(nbins+1))\n",
    "                                    h1.SetBinError(nbins, math.sqrt(pow(h1.GetBinError(nbins),2) + pow(h1.GetBinError(nbins+1),2)))\n",
    "                                    # if isMC:\n",
    "                                    #     h1.Scale(s.sigma*10**3/ntot_events[d.label][s.label])\n",
    "                                    histo_name = h1.GetName()\n",
    "                                    if \"nominal\" not in histo_name : h1.SetName(histo_name+\"_nominal\")\n",
    "                                    outfile.cd()\n",
    "                                    h1.Write()\n",
    "                                else:\n",
    "                                    for var_type in ['up', 'down']:\n",
    "                                        h1 = dict_h[d.label][s.label][reg][v._name][vari+\":\"+var_type]\n",
    "                                        # h1.SetName(h1.GetName()+\"_\"+vari+var_type.capitalize())\n",
    "                                        histo_name = h1.GetName()\n",
    "                                        if vari+\"_\"+var_type not in histo_name:\n",
    "                                            h1.SetName(h1.GetName()+\"_\"+vari+\"_\"+var_type)\n",
    "                                        nbins = h1.GetNbinsX()\n",
    "                                        h1.SetBinContent(1, h1.GetBinContent(0) + h1.GetBinContent(1))\n",
    "                                        h1.SetBinError(1, math.sqrt(pow(h1.GetBinError(0),2) + pow(h1.GetBinError(1),2)))\n",
    "                                        h1.SetBinContent(nbins, h1.GetBinContent(nbins) + h1.GetBinContent(nbins+1))\n",
    "                                        h1.SetBinError(nbins, math.sqrt(pow(h1.GetBinError(nbins),2) + pow(h1.GetBinError(nbins+1),2)))\n",
    "                                        # if isMC:\n",
    "                                        #     h1.Scale(s.sigma*10**3/ntot_events[d.label][s.label])\n",
    "                                        outfile.cd()\n",
    "                                        h1.Write()\n",
    "                            else:\n",
    "                                histo[reg][v._name] = dict_h[d.label][s.label][reg][v._name].GetValue()      \n",
    "                                nbins = histo[reg][v._name].GetNbinsX()\n",
    "                                histo[reg][v._name].SetBinContent(1, histo[reg][v._name].GetBinContent(0) + histo[reg][v._name].GetBinContent(1))\n",
    "                                histo[reg][v._name].SetBinError(1, math.sqrt(pow(histo[reg][v._name].GetBinError(0),2) + pow(histo[reg][v._name].GetBinError(1),2)))\n",
    "                                histo[reg][v._name].SetBinContent(nbins, histo[reg][v._name].GetBinContent(nbins) + histo[reg][v._name].GetBinContent(nbins+1))\n",
    "                                histo[reg][v._name].SetBinError(nbins, math.sqrt(pow(histo[reg][v._name].GetBinError(nbins),2) + pow(histo[reg][v._name].GetBinError(nbins+1),2)))\n",
    "                                # if isMC:\n",
    "                                #     histo[reg][v._name].Scale(s.sigma*10**3/ntot_events[d.label][s.label])\n",
    "                                outfile.cd()\n",
    "                                histo[reg][v._name].Write()\n",
    "                        else:\n",
    "                            histo[reg][v._name] = dict_h[d.label][s.label][reg][v._name].GetValue()\n",
    "                            nbins = histo[reg][v._name].GetNbinsX()\n",
    "                            histo[reg][v._name].SetBinContent(1, histo[reg][v._name].GetBinContent(0) + histo[reg][v._name].GetBinContent(1))\n",
    "                            histo[reg][v._name].SetBinError(1, math.sqrt(pow(histo[reg][v._name].GetBinError(0),2) + pow(histo[reg][v._name].GetBinError(1),2)))\n",
    "                            histo[reg][v._name].SetBinContent(nbins, histo[reg][v._name].GetBinContent(nbins) + histo[reg][v._name].GetBinContent(nbins+1))\n",
    "                            histo[reg][v._name].SetBinError(nbins, math.sqrt(pow(histo[reg][v._name].GetBinError(nbins),2) + pow(histo[reg][v._name].GetBinError(nbins+1),2)))\n",
    "                            # if isMC:\n",
    "                            #     histo[reg][v._name].Scale(s.sigma*10**3/ntot_events[d.label][s.label])\n",
    "                            outfile.cd()\n",
    "                            histo[reg][v._name].Write()\n",
    "        outfile.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b72ddfd-d641-437d-a78c-8568a0a17a30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"starting loop on datasets: \",[d.label for d in datasets])\n",
    "\n",
    "h = {}\n",
    "if do_variations:\n",
    "    h_varied = {}\n",
    "\n",
    "for d in datasets:\n",
    "    s_list = []\n",
    "    if hasattr(d, \"components\"):\n",
    "        s_list = d.components\n",
    "    else:\n",
    "        s_list = [d]\n",
    "    if 'Data' in d.label : sampleflag = 0\n",
    "    else: sampleflag = 1\n",
    "    \n",
    "    h[d.label] = {}\n",
    "    if do_variations:\n",
    "        h_varied[d.label]={}\n",
    "    for s in s_list:\n",
    "        #-------------------------------------------------------------------------\n",
    "        #########################  DF initialization #############################\n",
    "        #-------------------------------------------------------------------------\n",
    "        \n",
    "        print(\"Initializing DataFrame for \"+ s.label +\" chain len = \", len(chain[d.label][s.label]))\n",
    "        if len(chain[d.label][s.label])==1: print(chain[d.label][s.label])\n",
    "        if distributed ==True:\n",
    "            df = RDataFrame(\"Events\", chain[d.label][s.label], npartitions=nmaxpartition, \n",
    "                            daskclient=client, monitor_label = \"main\" )\n",
    "        else:\n",
    "            df = RDataFrame(\"Events\", chain[d.label][s.label])\n",
    "        df = df.Define(\"PuppiMET_T1_pt_nominal_vec\", \"RVec<float>{ (float) PuppiMET_T1_pt_nominal}\").Define(\"PuppiMET_T1_phi_nominal_vec\", \"RVec<float>{ (float) PuppiMET_T1_phi_nominal}\")\\\n",
    "               .Define(\"PuppiMET_T1_pt_jerdown_vec\", \"RVec<float>{ (float) PuppiMET_T1_pt_jerdown}\").Define(\"PuppiMET_T1_phi_jerdown_vec\", \"RVec<float>{ (float) PuppiMET_T1_phi_jerdown}\")\\\n",
    "               .Define(\"PuppiMET_T1_pt_jerup_vec\", \"RVec<float>{ (float) PuppiMET_T1_pt_jerup}\").Define(\"PuppiMET_T1_phi_jerup_vec\", \"RVec<float>{ (float) PuppiMET_T1_phi_jerup}\")\\\n",
    "               .Define(\"PuppiMET_T1_pt_jesTotaldown_vec\", \"RVec<float>{ (float) PuppiMET_T1_pt_jesTotaldown}\").Define(\"PuppiMET_T1_phi_jesTotaldown_vec\", \"RVec<float>{ (float) PuppiMET_T1_phi_jesTotaldown}\")\\\n",
    "               .Define(\"PuppiMET_T1_pt_jesTotalup_vec\", \"RVec<float>{ (float) PuppiMET_T1_pt_jesTotalup}\").Define(\"PuppiMET_T1_phi_jesTotalup_vec\", \"RVec<float>{ (float) PuppiMET_T1_phi_jesTotalup}\")\n",
    "        if do_variations:\n",
    "            df              = SF_variations(df)\n",
    "            df              = energetic_variations(df)\n",
    "        else:\n",
    "            df              = df\n",
    "        df_ismc         = df.Define(\"isMC\", \"isMC(\"+str(sampleflag)+\")\")\n",
    "        df_year         = df_ismc.Define(\"year\", str(s.year))\n",
    "        df_hemveto      = df_year.Define(\"HEMVeto\", \"hemveto(Jet_eta, Jet_phi, Electron_eta, Electron_phi)\")\n",
    "        df_hemveto      = df_hemveto.Filter(\"(isMC || (year != 2018) || (HEMVeto || run<319077.))\")\n",
    "        df_hlt          = trigger_filter(df_hemveto)\n",
    "        \n",
    "        df_hlt          = df_hlt.Define(\"w_nominal\", \"1\")\n",
    "            \n",
    "        if sampleflag: df_wnom = df_hlt.Redefine('w_nominal', 'w_nominal*puWeight')  \n",
    "        else: df_wnom          = df_hlt.Redefine('w_nominal', '1')\n",
    "\n",
    "        df_presel       = preselection(df_wnom)\n",
    "        df_topsel       = select_top(df_presel)\n",
    "        df_topsel       = df_topsel.Define(\"MT_T\", \"sqrt(2 * Top_pt * PuppiMET_T1_pt_nominal * (1 - cos(Top_phi - PuppiMET_T1_phi_nominal)))\")\n",
    "        \n",
    "        if len(var) != 0 :\n",
    "            h[d.label][s.label] = bookhisto(df_topsel, regions_def, var)\n",
    "        \n",
    "        if do_variations:\n",
    "            # h [dataset][label][region][variable]\n",
    "            print(\"applying vary\")\n",
    "            h_varied[d.label][s.label]={}\n",
    "            for reg in regions_def.keys():\n",
    "                h_varied[d.label][s.label][reg] = {}\n",
    "                for v in var:\n",
    "                    if distributed == True:\n",
    "                        h_varied[d.label][s.label][reg][v._name] = ROOT.RDF.Experimental.Distributed.VariationsFor(h[d.label][s.label][reg][v._name])\n",
    "                    else:\n",
    "                        h_varied[d.label][s.label][reg][v._name] = ROOT.RDF.Experimental.VariationsFor(h[d.label][s.label][reg][v._name])\n",
    "\n",
    "\n",
    "print(\"All histos booked !\")\n",
    "for d in datasets:\n",
    "    if len(var):\n",
    "        if do_variations:\n",
    "            print(h_varied.keys())\n",
    "            # print(h_varied[d.label].keys())\n",
    "            savehisto(d, h_varied, regions_def, var)\n",
    "        else:\n",
    "            savehisto(d, h, regions_def, var)\n",
    "    print(d.label + \" histos saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16fe229-69f3-4a0e-ae7c-c754c3fcda20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9573b747-9a5a-4501-b084-481b10d418ea",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = ROOT.TFile.Open(repohisto+s.label+\".root\")\n",
    "print(file)\n",
    "for a in file.GetListOfKeys(): print(a)\n",
    "for reg in regions_def.keys():\n",
    "    for v in var:\n",
    "        if do_variations:\n",
    "            hist = file.Get(v._name+\"_\"+reg+\"_nominal\")\n",
    "        else:\n",
    "            hist = file.Get(v._name+\"_\"+reg)\n",
    "        print(reg, hist.Integral())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3606a5b-e3ce-491d-a86a-6c02431ca435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Singularity kernel - Base ROOT 6.32.02 + CMSJMECalculator 0.2.0 + Correctionlib 2.6.1",
   "language": "python",
   "name": "singularity-kernel-root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
